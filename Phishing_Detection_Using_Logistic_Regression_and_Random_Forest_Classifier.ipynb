{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Libraries"
      ],
      "metadata": {
        "id": "9JUz5U4eaIZk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JK3U1JPWZ8x1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "plt.rcParams['figure.figsize'] = (12,6)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicting Phishing Web Page Using Machine Learning"
      ],
      "metadata": {
        "id": "m44Ju3io9BDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phishing is a method of trying to gather personal information using deceptive e-mails and websites.\n",
        "\n",
        "In this notebook, we will read the data and look at what are the features that can give us information on what are the attributes of a phishing website"
      ],
      "metadata": {
        "id": "_kQCP3iv9K-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the dataset"
      ],
      "metadata": {
        "id": "eF0-5X6jdavj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/khuynh22/Phishing-Detection/main/Phishing_Legitimate_full.csv\")"
      ],
      "metadata": {
        "id": "1942mAqidX3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting dataset"
      ],
      "metadata": {
        "id": "Ro8nkNwgdq9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this phase we will convert float64 and int64 data to type 32, by doing this we can save the memory usage and we can prepare the data for using with sklearn random forest later for training purpose\n",
        "\n",
        "As we can see the data has 10k rows and 50 columns including labels"
      ],
      "metadata": {
        "id": "n_eJIy-U9hvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float_cols = data.select_dtypes('float64').columns\n",
        "for c in float_cols:\n",
        "    data[c] = data[c].astype('float32')\n",
        "    \n",
        "int_cols = data.select_dtypes('int64').columns\n",
        "for c in int_cols:\n",
        "    data[c] = data[c].astype('int32')\n",
        "    \n",
        "data.info()"
      ],
      "metadata": {
        "id": "jCsIbPjXdYGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.rename(columns = {'CLASS_LABEL': 'labels'}, inplace = True)"
      ],
      "metadata": {
        "id": "GUcOk90PfiC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Viewing the data"
      ],
      "metadata": {
        "id": "pdK3XivygBPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.sample(5)"
      ],
      "metadata": {
        "id": "aKmWaRQtgDvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarizing Statistics"
      ],
      "metadata": {
        "id": "6jQBtj4egyj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using the describe method, we can see some of the columns have high variance and some have smaller variance, this is due to the fact that some of the column have bigger values and bigger ranges"
      ],
      "metadata": {
        "id": "36c_HaIe9y5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "BKcle4cJgnjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balanced/Imbalanced Checking"
      ],
      "metadata": {
        "id": "jds273vPhFNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['labels'].value_counts().plot(kind = 'bar')"
      ],
      "metadata": {
        "id": "H1fVnw1dhLVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spearman Correlation"
      ],
      "metadata": {
        "id": "KcBqXPY_hbtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By looking the spearman correlation, we can find which features are linearly correlated in terms of predicting if a site is phising or not"
      ],
      "metadata": {
        "id": "Z8yxpGgE-LpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr_heatmap(data, idx_s, idx_e):\n",
        "  y = data['labels']\n",
        "  temp = data.iloc[:, idx_s:idx_e]\n",
        "  if 'id' in temp.columns:\n",
        "    del temp['id']\n",
        "  temp[\"labels\"] = y\n",
        "  sns.heatmap(temp.corr(), annot= True, fmt = '.2f')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "wVpCXyRuhbeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heatmap of first 50 columns"
      ],
      "metadata": {
        "id": "bdOGTVhzi6Mw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By looking at the first 10 columns against labels, we can concluded that non of the features have strong correlation with the labels, however, NumDash has some significant negative effect towards the labels, which could mean if there is less number of dash then it is more likely to be phising site"
      ],
      "metadata": {
        "id": "hRPU4Oej-RlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First 10 columns\n",
        "corr_heatmap(data, 0, 10)"
      ],
      "metadata": {
        "id": "hJ7oCDnhiTYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Columns 10 to 20"
      ],
      "metadata": {
        "id": "c1-sxOJn-uhv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no strong or even medium level strength correlation features with labels"
      ],
      "metadata": {
        "id": "_3RRpFY0-wvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 11 to 20\n",
        "corr_heatmap(data, 10, 20)"
      ],
      "metadata": {
        "id": "0xE2BX9lloy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Columns 20 to 30"
      ],
      "metadata": {
        "id": "MQoUdori-6M_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Columns 20 to 30\n",
        "Still no strong correlation feature"
      ],
      "metadata": {
        "id": "VqQFViWG-9NV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 21 to 30\n",
        "corr_heatmap(data, 20, 30)"
      ],
      "metadata": {
        "id": "i5udnezxlo9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Columns 30 to 40"
      ],
      "metadata": {
        "id": "w7Rcqotm_J_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well here we have a few features that are linearly correlated to our dep variable\n",
        "\n",
        "* InsecureForms shows that as the value is higher so the probability of being a phising site\n",
        "\n",
        "* PctNullSelfRedirectHyperlinks shows the same positive correlation as InsecureForms\n",
        "\n",
        "* FequentDomainNameMismatch shows that it has medium linear correlation in positive direction\n",
        "\n",
        "* SubmitInfoToEmail seems to indicate that sites that ask users to submit their details to emails seems to be more high probability for phising"
      ],
      "metadata": {
        "id": "eMDDZMJU_L4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 31 to 40\n",
        "corr_heatmap(data, 30, 40)"
      ],
      "metadata": {
        "id": "17Sl5tYZlpGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Columns 40 to 50"
      ],
      "metadata": {
        "id": "w-WFgobP_k4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The only column in this group that has some correlation with labels is PctExtNullSelfRedirectHyperlinksRT and it has negative effect towards labels which could mean that when the number of percent of null self redirect hyperlinks occur hence the probabiliy of phising increases"
      ],
      "metadata": {
        "id": "yaZl4A8v_pAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 41 to 50\n",
        "corr_heatmap(data, 40, 50)"
      ],
      "metadata": {
        "id": "TAtcvUehlpSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mutual Info Classifier"
      ],
      "metadata": {
        "id": "1yJf6VOHgr67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use mutual info classifier to find non linear and linear correlation betweem the features and labels"
      ],
      "metadata": {
        "id": "4luN_cC4_ub-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_classif"
      ],
      "metadata": {
        "id": "Y82Wgj4Ug4Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(['id', 'labels'], axis = 1)\n",
        "y = data['labels']"
      ],
      "metadata": {
        "id": "bTEsqQ4YhKcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discrete_features = X.dtypes == int"
      ],
      "metadata": {
        "id": "9Yz_vrNYhWYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we process the scores and we can see that now mutual info is showing a bit different list from spearman corr"
      ],
      "metadata": {
        "id": "p2k8BPQO_6lK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the scores and compare with spearman corr\n",
        "mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features)\n",
        "mi_scores = pd.Series(mi_scores, name = 'MI Scores', index = X.columns)\n",
        "mi_scores = mi_scores.sort_values(ascending = False)\n",
        "mi_scores"
      ],
      "metadata": {
        "id": "gYUihjkYhgVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ny95ktK9AI2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_mi_scores(scores):\n",
        "    scores = scores.sort_values(ascending=True)\n",
        "    width = np.arange(len(scores))\n",
        "    ticks = list(scores.index)\n",
        "    plt.barh(width, scores)\n",
        "    plt.yticks(width, ticks)\n",
        "    plt.title(\"MI Scores\")\n",
        "    \n",
        "plt.figure(dpi=100, figsize=(12,12))\n",
        "plot_mi_scores(mi_scores)"
      ],
      "metadata": {
        "id": "0FJDyg-8iaW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prediction\n",
        "We will first use logistic regression as for baseline, then try to beat the baseline using random forest classifer\n",
        "\n",
        "Our evaluation metrics will be accuracy, precision, recall and f1 score\n",
        "\n",
        "Below we import all the required modules"
      ],
      "metadata": {
        "id": "wPQzSCRDoBHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# !cp ../input/rapids/rapids.0.15.0 /opt/conda/envs/rapids.tar.gz\n",
        "# !cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\n",
        "# sys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\n",
        "# sys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\n",
        "# sys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n",
        "# !cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier as cuRfc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "ujLad0Yen_LK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train logistic models\n",
        "This method is to perform a repetative training process using logistic regression model, the purpose for this is to find the optimal number of features that can be used to find the best fitted model without adjusting much of the hyperparameters, hence the idea here is to go with Data-Centric training, basically the method takes number of top N features to be used for training the model and all the evaluation metrics are returned for evaluation purpose"
      ],
      "metadata": {
        "id": "0huOEAZHoJAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_logistic(data, top_n):\n",
        "    top_n_features = mi_scores.sort_values(ascending=False).head(top_n).index.tolist()\n",
        "    X = data[top_n_features]\n",
        "    y = data['labels']\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "    \n",
        "    lr = LogisticRegression(max_iter=10000)\n",
        "    lr.fit(X_train, y_train)\n",
        "    \n",
        "    y_pred = lr.predict(X_test)\n",
        "    \n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    \n",
        "    return precision, recall, f1, accuracy"
      ],
      "metadata": {
        "id": "zdmKU-AQoInD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the loop will be starting from 20 as we will start training with top 20 features up to all 50 features to find optimal number of features needed for this problem"
      ],
      "metadata": {
        "id": "An0t3ZvAoOF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = []\n",
        "for i in range(20,51,1):\n",
        "    precision, recall, f1, accuracy = train_logistic(data, i)\n",
        "    print(\"Performance for Logistic Model with Top {} features is precision : {}, recall : {}, f1 score : {}, accuracy : {}\".format(i, precision, recall, f1, accuracy))\n",
        "    arr.append([i, precision, recall, f1, accuracy])"
      ],
      "metadata": {
        "id": "XDPeM5yGoPkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(arr, columns=['num_of_features', 'precision', 'recall', 'f1_score', 'accuracy'])\n",
        "df"
      ],
      "metadata": {
        "id": "YJMRSG4qpkiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Logistic Regression Performance"
      ],
      "metadata": {
        "id": "pep1qf26qAqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the model had ups and downs during the training as more number of features were added, as our target is to maximize all the metrics we have to find the number of features that gives us the best of all metrics, from the figure below, we can see that recall is constantly performing good but our model tend to have problem with precision score, hence to choose the best N of features, we have to pick the area where all the metrics are performing and based on the figure I would say its around 39 features"
      ],
      "metadata": {
        "id": "6hPQrEDRApOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lineplot(x = 'num_of_features', y = 'precision', data = df, label = 'Precision Score')\n",
        "sns.lineplot(x = 'num_of_features', y = 'recall', data = df, label = 'Recall Score')\n",
        "sns.lineplot(x = 'num_of_features', y = 'f1_score', data = df, label = 'F1 Score')\n",
        "sns.lineplot(x = 'num_of_features', y = 'accuracy', data = df, label = 'Accuracy Score')"
      ],
      "metadata": {
        "id": "HDvyHNqqqGM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Random Forest Classifier on GPU"
      ],
      "metadata": {
        "id": "ERE8vVsRBC7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is the same method as logistic reg, the only diff is that we are now using random forest classifier for training and trying to beat the logistic baseline"
      ],
      "metadata": {
        "id": "ZgSqGuzeBGXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_rfc(data, top_n):\n",
        "    top_n_features = mi_scores.sort_values(ascending=False).head(top_n).index.tolist()\n",
        "    X = data[top_n_features]\n",
        "    y = data['labels']\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "    \n",
        "    rfc = cuRfc(n_estimators=500, \n",
        "                criterion=\"gini\",  \n",
        "                max_depth=32, \n",
        "                max_features=1.0,\n",
        "                n_jobs=128)\n",
        "    \n",
        "    rfc.fit(X_train, y_train)\n",
        "    \n",
        "    y_pred = rfc.predict(X_test)\n",
        "    \n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    \n",
        "    return precision, recall, f1, accuracy"
      ],
      "metadata": {
        "id": "ob0igE0IBQ4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = []\n",
        "for i in range(20,51,1):\n",
        "    precision, recall, f1, accuracy = train_rfc(data, i)\n",
        "    print(\"Performance for RFC Model with Top {} features is precision : {}, recall : {}, f1 score : {}, accuracy : {}\".format(i, precision, recall, f1, accuracy))\n",
        "    arr.append([i, precision, recall, f1, accuracy])"
      ],
      "metadata": {
        "id": "CqkhCDMgBT7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(arr, columns=['num_of_features', 'precision', 'recall', 'f1_score', 'accuracy'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "0kG67c4GBbPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualize Random Forest Performance"
      ],
      "metadata": {
        "id": "53UhUPyKEcz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our goal is to beat logistic regression baseline which is\n",
        "\n",
        "* accuracy = 0.947162\n",
        "* precision = 0.957468\n",
        "* recall = 0.952287\n",
        "* f1_score = 0.9515\n",
        "\n",
        "So by visualizing the figure below, we can conclude that the best number of features for this model would be 32, one less than logistic regression, the reason why I chose 32 is because that is the number of features that allowed the model to perform the best across all the evaluation metric"
      ],
      "metadata": {
        "id": "hFSsqY7ZEf-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lineplot(x='num_of_features', y='precision', data=df, label='Precision Score')\n",
        "sns.lineplot(x='num_of_features', y='recall', data=df, label='Recall Score')\n",
        "sns.lineplot(x='num_of_features', y='f1_score', data=df, label='F1 Score')\n",
        "sns.lineplot(x='num_of_features', y='accuracy', data=df, label='Acc Score')"
      ],
      "metadata": {
        "id": "qY_K-G_kEnFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Final Random Forest Mode"
      ],
      "metadata": {
        "id": "DiqyF0IyEssU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets train the final random forest model based on the optimal N number of features"
      ],
      "metadata": {
        "id": "Z7n9WtT_Ev9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_n_features = mi_scores.sort_values(ascending=False).head(32).index.tolist()\n",
        "X = data[top_n_features]\n",
        "y = data['labels']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "rfc = cuRfc(n_estimators=500, \n",
        "            criterion=\"gini\",  \n",
        "            max_depth=32, \n",
        "            max_features=1.0,\n",
        "            n_jobs=128)\n",
        "\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Performance for RFC Model with Top {} features is precision : {}, recall : {}, f1 score : {}, accuracy : {}\".format(27, precision, recall, f1, accuracy))"
      ],
      "metadata": {
        "id": "2K-xRlSJE06F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Performance"
      ],
      "metadata": {
        "id": "uNH_c6JXFR_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is now capable of predicting at up to 98% accuracy and also precision and recall, this shows the model has high confidence in predicting phishing or non-phishing site"
      ],
      "metadata": {
        "id": "ZSHt6_sbFUGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "U4pZacIXFbr9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}