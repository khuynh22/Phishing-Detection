{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["##Importing Libraries"],"metadata":{"id":"9JUz5U4eaIZk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JK3U1JPWZ8x1"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","pd.set_option('display.max_columns', None)\n","plt.rcParams['figure.figsize'] = (12,6)"]},{"cell_type":"markdown","source":["## Loading dataset"],"metadata":{"id":"eF0-5X6jdavj"}},{"cell_type":"code","source":["data = pd.read_csv(\"Phishing_Legitimate_full.csv\")"],"metadata":{"id":"1942mAqidX3T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Converting dataset"],"metadata":{"id":"Ro8nkNwgdq9g"}},{"cell_type":"code","source":["float_cols = data.select_dtypes('float64').columns\n","for c in float_cols:\n","  data[c] = data[c].astype('float32')\n","\n","int_cols = data.select_dtypes('int64').columns\n","for c in int_cols:\n","  data[c] = data[c].astype('int32')\n","# data.info()"],"metadata":{"id":"jCsIbPjXdYGQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.rename(columns = {'CLASS_LABEL': 'labels'}, inplace = True)"],"metadata":{"id":"GUcOk90PfiC_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## View the data"],"metadata":{"id":"pdK3XivygBPQ"}},{"cell_type":"code","source":["data.sample(5)"],"metadata":{"id":"aKmWaRQtgDvQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Summary Statistics"],"metadata":{"id":"6jQBtj4egyj_"}},{"cell_type":"code","source":["data.describe()"],"metadata":{"id":"BKcle4cJgnjq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Balance Check"],"metadata":{"id":"jds273vPhFNZ"}},{"cell_type":"code","source":["data['labels'].value_counts().plot(kind = 'bar')"],"metadata":{"id":"H1fVnw1dhLVT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Spearman Correlation"],"metadata":{"id":"KcBqXPY_hbtj"}},{"cell_type":"code","source":["def corr_heatmap(data, idx_s, idx_e):\n","  y = data['labels']\n","  temp = data.iloc[:, idx_s:idx_e]\n","  if 'id' in temp.columns:\n","    del temp['id']\n","  temp[\"labels\"] = y\n","  sns.heatmap(temp.corr(), annot= True, fmt = '.2f')\n","  plt.show()"],"metadata":{"id":"wVpCXyRuhbeG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Heatmap of first 50 columns"],"metadata":{"id":"bdOGTVhzi6Mw"}},{"cell_type":"code","source":["# First 10 columns\n","corr_heatmap(data, 0, 10)"],"metadata":{"id":"hJ7oCDnhiTYm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Column 11 to 20\n","corr_heatmap(data, 10, 20)"],"metadata":{"id":"0xE2BX9lloy1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Column 21 to 30\n","corr_heatmap(data, 20, 30)"],"metadata":{"id":"i5udnezxlo9m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Column 31 to 40\n","corr_heatmap(data, 30, 40)"],"metadata":{"id":"17Sl5tYZlpGC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Column 41 to 50\n","corr_heatmap(data, 40, 50)"],"metadata":{"id":"TAtcvUehlpSD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Mutual Info Classifier"],"metadata":{"id":"1yJf6VOHgr67"}},{"cell_type":"code","source":["from sklearn.feature_selection import mutual_info_classif"],"metadata":{"id":"Y82Wgj4Ug4Gl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = data.drop(['id', 'labels'], axis = 1)\n","y = data['labels']"],"metadata":{"id":"bTEsqQ4YhKcx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["discrete_features = X.dtypes == int"],"metadata":{"id":"9Yz_vrNYhWYa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Process the scores and compare with spearman corr\n","mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features)\n","mi_scores = pd.Series(mi_scores, name = 'MI Scores', index = X.columns)\n","mi_scores = mi_scores.sort_values(ascending = False)\n","mi_scores"],"metadata":{"id":"gYUihjkYhgVB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_mi_scores(scores):\n","  # Graph_name: MI Scores\n","  plt.figure(figsize = (15, 10))\n","  mi_scores.plot.bar(x=None, y=None)\n","  plt.show()"],"metadata":{"id":"0FJDyg-8iaW8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(dpi = 100, figsize = (12, 12))\n","plot_mi_scores(mi_scores)"],"metadata":{"id":"dY01I-GgnAzX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Prediction\n","We will first use logistic regression as for baseline, then try to beat the baseline using random forest classifer\n","\n","Our evaluation metrics will be accuracy, precision, recall and f1 score\n","\n","Below we import all the required modules"],"metadata":{"id":"wPQzSCRDoBHE"}},{"cell_type":"code","source":["!nvidia-smi\n","!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n","!python rapidsai-csp-utils/colab/env-check.py\n","!bash rapidsai-csp-utils/colab/update_gcc.sh\n","import os\n","os._exit(00)\n","import condacolab\n","condacolab.install()\n","import condacolab\n","condacolab.check()\n","!python rapidsai-csp-utils/colab/install_rapids.py stable\n","import os\n","os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n","os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n","os.environ['CONDA_PREFIX'] = '/usr/local'\n","from sklearn.linear_model import LogisticRegression\n","from cuml.ensemble import RandomForestClassifier as cuRfc\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"],"metadata":{"id":"ujLad0Yen_LK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Train logistic models\n","This method is to perform a repetative training process using logistic regression model, the purpose for this is to find the optimal number of features that can be used to find the best fitted model without adjusting much of the hyperparameters, hence the idea here is to go with Data-Centric training, basically the method takes number of top N features to be used for training the model and all the evaluation metrics are returned for evaluation purpose"],"metadata":{"id":"0huOEAZHoJAV"}},{"cell_type":"code","source":["def train_logistic(data, top_n):\n","    top_n_features = mi_scores.sort_values(ascending=False).head(top_n).index.tolist()\n","    X = data[top_n_features]\n","    y = data['labels']\n","    \n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n","    \n","    lr = LogisticRegression(max_iter=10000)\n","    lr.fit(X_train, y_train)\n","    \n","    y_pred = lr.predict(X_test)\n","    \n","    precision = precision_score(y_test, y_pred)\n","    recall = recall_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    \n","    return precision, recall, f1, accuracy"],"metadata":{"id":"zdmKU-AQoInD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here the loop will be starting from 20 as we will start training with top 20 features up to all 50 features to find optimal number of features needed for this problem"],"metadata":{"id":"An0t3ZvAoOF6"}},{"cell_type":"code","source":["arr = []\n","for i in range(20,51,1):\n","    precision, recall, f1, accuracy = train_logistic(data, i)\n","    print(\"Performance for Logistic Model with Top {} features is precision : {}, recall : {}, f1 score : {}, accuracy : {}\".format(i, precision, recall, f1, accuracy))\n","    arr.append([i, precision, recall, f1, accuracy])"],"metadata":{"id":"XDPeM5yGoPkL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame(arr, columns=['num_of_features', 'precision', 'recall', 'f1_score', 'accuracy'])\n","df"],"metadata":{"id":"YJMRSG4qpkiv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Visualize Logistic Regression Performance"],"metadata":{"id":"pep1qf26qAqV"}},{"cell_type":"code","source":["sns.lineplot(x = 'num_of_features', y = 'precision', data = df, label = 'Precision Score')\n","sns.lineplot(x = 'num_of_features', y = 'recall', data = df, label = 'Recall Score')\n","sns.lineplot(x = 'num_of_features', y = 'f1_score', data = df, label = 'F1 Score')\n","sns.lineplot(x = 'num_of_features', y = 'accuracy', data = df, label = 'Accuracy Score')"],"metadata":{"id":"HDvyHNqqqGM0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QkivMjH-qaIe"},"execution_count":null,"outputs":[]}]}